import streamlit as st
from langchain.memory import ConversationBufferMemory
from utils4 import qa_agent

st.title("ğŸ“‘ AIæ™ºèƒ½PDFé—®ç­”å·¥å…· ")

# å°è¯•ä»ä¼šè¯çŠ¶æ€è·å– OpenAI API å¯†é’¥ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ˜¾ç¤ºè¾“å…¥æ¡†
if 'openai_api_key' not in st.session_state:
    openai_api_key = st.text_input("è¯·è¾“å…¥OpenAI API Keyï¼š", type="password")
    if openai_api_key:
        st.session_state.openai_api_key = openai_api_key

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ä¸­çš„è®°å¿†
if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history",
        output_key="answer"
    )

uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„PDFæ–‡ä»¶ï¼š", type="pdf")
question = st.text_input("å¯¹PDFå†…å®¹è¿›è¡Œæé—®", disabled=not uploaded_file)

if uploaded_file and question:
    if 'openai_api_key' not in st.session_state or not st.session_state['openai_api_key']:
        st.info("è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥")
    elif st.session_state['openai_api_key']:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            response = qa_agent(st.session_state['openai_api_key'], st.session_state["memory"],
                                uploaded_file, question)

            if response:
                st.write("### ç­”æ¡ˆ")
                st.write(response["answer"])
                st.session_state["chat_history"] = response["chat_history"]

if "chat_history" in st.session_state:
    with st.expander("å†å²æ¶ˆæ¯"):
        for i in range(0, len(st.session_state["chat_history"]), 2):
            human_message = st.session_state["chat_history"][i]
            ai_message = st.session_state["chat_history"][i + 1]
            st.write(f"**ä½ **ï¼š{human_message.content}")
            st.write(f"**AI**ï¼š{ai_message.content}")
            if i < len(st.session_state["chat_history"]) - 2:
                st.divider()
